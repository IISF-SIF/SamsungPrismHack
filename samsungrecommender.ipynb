{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7806407,"sourceType":"datasetVersion","datasetId":4571626}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Custom Samsung Chatbot Recommender System**","metadata":{}},{"cell_type":"markdown","source":"### Links to the repository and code:\n\n- [Repository](https://github.com/IISF-SIF/SamsungPrismHack)\n- [Code](https://github.com/IISF-SIF/SamsungPrismHack/blob/main/samsungrecommender.ipynb)\n","metadata":{}},{"cell_type":"markdown","source":" # Setting Up Environment and Importing Libraries","metadata":{}},{"cell_type":"markdown","source":"### *Here we setup the intent classifier from the custom created samsung prompt dataset that is now open-source on Kaggle. The dataset was created across 10 different classes with a total of 967 diverse datapoints. The dataset was created using GPT 3.5, the goal of this recommender system is increase ease-of-use among users when using Samsung IoT Devices*","metadata":{}},{"cell_type":"markdown","source":"### **Intent Dataset Creation using BERTClassifer From User History**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Importing necessary libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Importing the os module to interact with the operating system\nimport os\n\n# Iterating through files in the input directory and printing their names\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T12:37:23.075117Z","iopub.execute_input":"2024-04-02T12:37:23.075832Z","iopub.status.idle":"2024-04-02T12:37:23.461105Z","shell.execute_reply.started":"2024-04-02T12:37:23.075788Z","shell.execute_reply":"2024-04-02T12:37:23.460149Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/samsungrecommend/RecommenderSamsungDevice - Sheet1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Installing necessary libraries using pip\n!pip install tqdm transformers torch\n\n# Importing required libraries\nimport pandas as pd  # For data manipulation\nimport torch  # PyTorch library for deep learning\nfrom tqdm.notebook import tqdm  # For progress bar\n\n# Importing BERT tokenizer from Hugging Face Transformers library\nfrom transformers import BertTokenizer\n\n# Importing TensorDataset for creating datasets\nfrom torch.utils.data import TensorDataset\n\n# Importing BERT model for sequence classification from Transformers library\nfrom transformers import BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:23.462691Z","iopub.execute_input":"2024-04-02T12:37:23.463061Z","iopub.status.idle":"2024-04-02T12:37:39.562576Z","shell.execute_reply.started":"2024-04-02T12:37:23.463011Z","shell.execute_reply":"2024-04-02T12:37:39.561502Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"# Reading the CSV file into a pandas DataFrame\ndata = pd.read_csv('/kaggle/input/samsungrecommend/RecommenderSamsungDevice - Sheet1.csv')\n\n# Displaying the first few rows of the DataFrame\ndata.head()\n\n# Counting the occurrences of each unique value in the 'Query' column\ndata['Query'].value_counts()\n\n# Extracting unique values from the 'Query' column and assigning them to the variable 'possible_labels'\npossible_labels = data.Query.unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:39.563738Z","iopub.execute_input":"2024-04-02T12:37:39.564124Z","iopub.status.idle":"2024-04-02T12:37:39.597078Z","shell.execute_reply.started":"2024-04-02T12:37:39.564100Z","shell.execute_reply":"2024-04-02T12:37:39.596367Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Creating an empty dictionary to store label mappings\nlabel_dict = {}\n\n# Iterating through the unique labels in possible_labels along with their index using enumerate\nfor index, possible_label in enumerate(possible_labels):\n    # Assigning each unique label to its corresponding index in the dictionary\n    label_dict[possible_label] = index\n\n# Displaying the label dictionary\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:39.599513Z","iopub.execute_input":"2024-04-02T12:37:39.600093Z","iopub.status.idle":"2024-04-02T12:37:39.607095Z","shell.execute_reply.started":"2024-04-02T12:37:39.600067Z","shell.execute_reply":"2024-04-02T12:37:39.606185Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Phone': 0,\n 'Tab': 1,\n 'TV': 2,\n 'AC': 3,\n 'Wash': 4,\n 'Fridge': 5,\n 'Vacuum': 6,\n 'Dish': 7,\n 'Micro': 8,\n 'Watch': 9}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocessing and Splitting","metadata":{}},{"cell_type":"code","source":"# Replacing labels in the 'Query' column with their corresponding indices from the label_dict dictionary\ndata['label'] = data.Query.replace(label_dict)\n\n# Importing train_test_split function from scikit-learn\nfrom sklearn.model_selection import train_test_split\n\n# Splitting the data into training and validation sets\n# X_train, X_val: Indices of training and validation data\n# y_train, y_val: Labels corresponding to the training and validation data\n# test_size: Proportion of the dataset to include in the validation split\n# random_state: Seed for random number generation for reproducibility\n# stratify: Ensures that the distribution of labels is similar in both training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(data.index.values, \n                                                  data.label.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=data.label.values)\n\n# Adding a new column 'data_type' to the DataFrame to indicate whether each row belongs to the training or validation set\ndata['data_type'] = ['not_set']*data.shape[0]\n\n# Marking rows corresponding to training and validation indices with 'train' and 'val' respectively\ndata.loc[X_train, 'data_type'] = 'train'\ndata.loc[X_val, 'data_type'] = 'val'\n\n# Grouping the data by 'Query', 'label', and 'data_type' columns and counting the occurrences of each group\ndata.groupby(['Query', 'label', 'data_type']).count()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:39.608157Z","iopub.execute_input":"2024-04-02T12:37:39.608430Z","iopub.status.idle":"2024-04-02T12:37:41.015992Z","shell.execute_reply.started":"2024-04-02T12:37:39.608408Z","shell.execute_reply":"2024-04-02T12:37:41.015021Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_72/1309740842.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  data['label'] = data.Query.replace(label_dict)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                        Input\nQuery  label data_type       \nAC     3     train         85\n             val           15\nDish   7     train         85\n             val           15\nFridge 5     train         85\n             val           15\nMicro  8     train         85\n             val           15\nPhone  0     train         85\n             val           15\nTV     2     train         85\n             val           15\nTab    1     train         85\n             val           15\nVacuum 6     train         85\n             val           15\nWash   4     train         85\n             val           15\nWatch  9     train         85\n             val           15","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Input</th>\n    </tr>\n    <tr>\n      <th>Query</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">AC</th>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Dish</th>\n      <th rowspan=\"2\" valign=\"top\">7</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Fridge</th>\n      <th rowspan=\"2\" valign=\"top\">5</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Micro</th>\n      <th rowspan=\"2\" valign=\"top\">8</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Phone</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">TV</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Tab</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Vacuum</th>\n      <th rowspan=\"2\" valign=\"top\">6</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Wash</th>\n      <th rowspan=\"2\" valign=\"top\">4</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Watch</th>\n      <th rowspan=\"2\" valign=\"top\">9</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenization and Encoding","metadata":{}},{"cell_type":"code","source":"# Importing the BERT tokenizer from the Hugging Face Transformers library and loading the 'bert-base-uncased' model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n                                          \n# Tokenizing and encoding the training data\nencoded_data_train = tokenizer.batch_encode_plus(\n    data[data.data_type=='train'].Input.values,  # Extracting input text data for the training set\n    add_special_tokens=True,  # Adding special tokens like [CLS] and [SEP]\n    return_attention_mask=True,  # Returning attention masks to indicate which tokens are padding tokens\n    pad_to_max_length=True,  # Padding sequences to the maximum length\n    max_length=256,  # Maximum sequence length\n    return_tensors='pt'  # Returning PyTorch tensors\n)\n\n# Tokenizing and encoding the validation data\nencoded_data_val = tokenizer.batch_encode_plus(\n    data[data.data_type=='val'].Input.values,  # Extracting input text data for the validation set\n    add_special_tokens=True,  # Adding special tokens like [CLS] and [SEP]\n    return_attention_mask=True,  # Returning attention masks to indicate which tokens are padding tokens\n    pad_to_max_length=True,  # Padding sequences to the maximum length\n    max_length=256,  # Maximum sequence length\n    return_tensors='pt'  # Returning PyTorch tensors\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:41.017315Z","iopub.execute_input":"2024-04-02T12:37:41.017983Z","iopub.status.idle":"2024-04-02T12:37:42.935219Z","shell.execute_reply.started":"2024-04-02T12:37:41.017944Z","shell.execute_reply":"2024-04-02T12:37:42.934211Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04a44c71743d4774bdebfebc45f38c52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e332b9ad0b4323910c7307c31aeefb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b2da0b90fc49a19ea092f51db4a433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c8ef66b1db34262981a661665cd4796"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Creation","metadata":{}},{"cell_type":"code","source":"# Extracting input IDs, attention masks, and labels for the training set\ninput_ids_train = encoded_data_train['input_ids']  # Extracting input IDs\nattention_masks_train = encoded_data_train['attention_mask']  # Extracting attention masks\nlabels_train = torch.tensor(data[data.data_type=='train'].label.values)  # Extracting labels and converting to PyTorch tensor\n\n# Extracting input IDs, attention masks, and labels for the validation set\ninput_ids_val = encoded_data_val['input_ids']  # Extracting input IDs\nattention_masks_val = encoded_data_val['attention_mask']  # Extracting attention masks\nlabels_val = torch.tensor(data[data.data_type=='val'].label.values)  # Extracting labels and converting to PyTorch tensor\n\n# Creating a TensorDataset for the training set, which combines input IDs, attention masks, and labels\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n\n# Creating a TensorDataset for the validation set, which combines input IDs, attention masks, and labels\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:42.936594Z","iopub.execute_input":"2024-04-02T12:37:42.937292Z","iopub.status.idle":"2024-04-02T12:37:42.969927Z","shell.execute_reply.started":"2024-04-02T12:37:42.937255Z","shell.execute_reply":"2024-04-02T12:37:42.968909Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model Initialization","metadata":{}},{"cell_type":"code","source":"# Importing the BERT model for sequence classification from the Hugging Face Transformers library\nfrom transformers import BertForSequenceClassification\n\n# Initializing the BERT model for sequence classification\n# - \"bert-base-uncased\": Pre-trained BERT model\n# - num_labels: Number of unique labels in the dataset, determined by the length of label_dict\n# - output_attentions: Whether to return attentions weights of all layers\n# - output_hidden_states: Whether to return hidden states of all layers\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:42.971216Z","iopub.execute_input":"2024-04-02T12:37:42.971574Z","iopub.status.idle":"2024-04-02T12:37:46.644500Z","shell.execute_reply.started":"2024-04-02T12:37:42.971543Z","shell.execute_reply":"2024-04-02T12:37:46.643776Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de94ddfb63945b48ac0ed90d2331f25"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Loaders and Optimizer","metadata":{}},{"cell_type":"code","source":"# Importing necessary classes from torch.utils.data for creating data loaders\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\n# Setting the batch size for training and validation data loaders\nbatch_size = 3\n\n# Creating a data loader for the training dataset\ndataloader_train = DataLoader(dataset_train,  # Training dataset\n                              sampler=RandomSampler(dataset_train),  # Random sampler for shuffling\n                              batch_size=batch_size)  # Batch size for training\n\n# Creating a data loader for the validation dataset\ndataloader_validation = DataLoader(dataset_val,  # Validation dataset\n                                   sampler=SequentialSampler(dataset_val),  # Sequential sampler for iterating through the dataset\n                                   batch_size=batch_size)  # Batch size for validation\n\n# Importing the AdamW optimizer and the learning rate scheduler from the Hugging Face Transformers library\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\n# Initializing the AdamW optimizer with the BERT model parameters\n# - model.parameters(): Parameters of the BERT model\n# - lr: Learning rate (1e-5)\n# - eps: Epsilon parameter (small value to avoid division by zero)\noptimizer = AdamW(model.parameters(),\n                  lr=1e-5,  # Learning rate\n                  eps=1e-8)  # Epsilon value for numerical stability","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:46.645735Z","iopub.execute_input":"2024-04-02T12:37:46.646110Z","iopub.status.idle":"2024-04-02T12:37:46.664420Z","shell.execute_reply.started":"2024-04-02T12:37:46.646076Z","shell.execute_reply":"2024-04-02T12:37:46.663615Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training Parameters","metadata":{}},{"cell_type":"code","source":"# Setting the number of epochs for training\nepochs = 5\n\n# Initializing the learning rate scheduler\n# - get_linear_schedule_with_warmup: Creates a schedule with a learning rate that linearly increases from 0 during warmup steps\n# - optimizer: Optimizer to be used (AdamW optimizer in this case)\n# - num_warmup_steps: Number of warmup steps (0 in this case, meaning no warmup)\n# - num_training_steps: Total number of training steps (number of batches per epoch multiplied by the number of epochs)\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:46.667656Z","iopub.execute_input":"2024-04-02T12:37:46.667905Z","iopub.status.idle":"2024-04-02T12:37:46.671906Z","shell.execute_reply.started":"2024-04-02T12:37:46.667884Z","shell.execute_reply":"2024-04-02T12:37:46.671073Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation Metrics","metadata":{}},{"cell_type":"code","source":"# Importing necessary function from scikit-learn for F1 score calculation\nfrom sklearn.metrics import f1_score\n\n# Defining a function to calculate F1 score\ndef f1_score_func(preds, labels):\n    # Flatten the predicted and true labels to 1D arrays\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    # Calculate the weighted F1 score\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\n# Defining a function to calculate accuracy per class\ndef accuracy_per_class(preds, labels):\n    # Reverse the label dictionary to map label indices to their corresponding labels\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    # Flatten the predicted and true labels to 1D arrays\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n\n    # Iterate over unique labels\n    for label in np.unique(labels_flat):\n        # Extract predictions and true labels for the current class\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        \n        # Print class name, accuracy, and total count of correct predictions for the current class\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:46.673137Z","iopub.execute_input":"2024-04-02T12:37:46.673524Z","iopub.status.idle":"2024-04-02T12:37:46.681703Z","shell.execute_reply.started":"2024-04-02T12:37:46.673493Z","shell.execute_reply":"2024-04-02T12:37:46.680757Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Setting Random Seeds and Device","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport random\nimport numpy as np\n\n# Setting the seed value for random number generation\nseed_val = 17\n\n# Setting the seed for Python's built-in random number generator\nrandom.seed(seed_val)\n\n# Setting the seed for NumPy's random number generator\nnp.random.seed(seed_val)\n\n# Setting the seed for PyTorch's random number generator\ntorch.manual_seed(seed_val)\n\n# Setting the seed for PyTorch's CUDA random number generator (if available)\ntorch.cuda.manual_seed_all(seed_val)\n\n# Checking if GPU is available and assigning the appropriate device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Moving the model to the selected device\nmodel.to(device)\n\n# Printing the selected device (CPU or GPU)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:46.682606Z","iopub.execute_input":"2024-04-02T12:37:46.682837Z","iopub.status.idle":"2024-04-02T12:37:47.012917Z","shell.execute_reply.started":"2024-04-02T12:37:46.682817Z","shell.execute_reply":"2024-04-02T12:37:47.012120Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation Function","metadata":{}},{"cell_type":"code","source":"def evaluate(dataloader_val):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    # Initialize variables to store total loss, predictions, and true values\n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    # Iterate over batches in the validation data loader\n    for batch in dataloader_val:\n        # Move batch to the appropriate device (CPU or GPU)\n        batch = tuple(b.to(device) for b in batch)\n        \n        # Unpack inputs from the batch\n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        # Disable gradient calculation during evaluation\n        with torch.no_grad():        \n            # Forward pass through the model\n            outputs = model(**inputs)\n            \n        # Extract loss and logits from the model outputs\n        loss = outputs[0]\n        logits = outputs[1]\n        \n        # Accumulate the total validation loss\n        loss_val_total += loss.item()\n\n        # Detach logits from the computation graph and move them to CPU\n        logits = logits.detach().cpu().numpy()\n        # Move label ids to CPU\n        label_ids = inputs['labels'].cpu().numpy()\n        \n        # Append predictions and true labels to the respective lists\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    # Calculate average validation loss\n    loss_val_avg = loss_val_total / len(dataloader_val) \n    \n    # Concatenate predictions and true labels across all batches\n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:47.013950Z","iopub.execute_input":"2024-04-02T12:37:47.014257Z","iopub.status.idle":"2024-04-02T12:37:47.024564Z","shell.execute_reply.started":"2024-04-02T12:37:47.014231Z","shell.execute_reply":"2024-04-02T12:37:47.023674Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"# Iterate through each epoch\nfor epoch in tqdm(range(1, epochs+1)):\n    \n    # Set the model to training mode\n    model.train()\n    \n    # Initialize total training loss for the epoch\n    loss_train_total = 0\n\n    # Display progress bar for the epoch\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    \n    # Iterate through batches in the training data loader\n    for batch in progress_bar:\n        # Reset gradients\n        model.zero_grad()\n        \n        # Move batch to the appropriate device (CPU or GPU)\n        batch = tuple(b.to(device) for b in batch)\n        \n        # Unpack inputs from the batch\n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        # Forward pass through the model\n        outputs = model(**inputs)\n        \n        # Extract loss from the model outputs\n        loss = outputs[0]\n        loss_train_total += loss.item()\n        \n        # Backward pass: Compute gradients\n        loss.backward()\n\n        # Clip gradients to prevent explosion\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update model parameters\n        optimizer.step()\n        # Update learning rate scheduler\n        scheduler.step()\n        \n        # Update progress bar with current training loss\n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n    \n    # Save the model at the end of each epoch\n    torch.save(model.state_dict(), f'/kaggle/working/finetuned_BERT_epoch_{epoch}.model')\n        \n    # Print epoch information\n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    # Calculate average training loss for the epoch\n    loss_train_avg = loss_train_total / len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    # Evaluate the model on the validation dataset\n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    \n    # Calculate F1 score on the validation dataset\n    val_f1 = f1_score_func(predictions, true_vals)\n    \n    # Print validation loss and F1 score\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:37:47.025634Z","iopub.execute_input":"2024-04-02T12:37:47.025900Z","iopub.status.idle":"2024-04-02T12:41:46.432036Z","shell.execute_reply.started":"2024-04-02T12:37:47.025878Z","shell.execute_reply":"2024-04-02T12:41:46.430972Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebff7cf475d4b978846c7ef6a38d09e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1\nTraining loss: 2.0034334013159847\nValidation loss: 1.2490992045402527\nF1 Score (Weighted): 0.9276517419925127\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 2\nTraining loss: 0.8281914902929689\nValidation loss: 0.3915663495659828\nF1 Score (Weighted): 0.9538515137069086\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 3\nTraining loss: 0.3226675465178322\nValidation loss: 0.22756596557796002\nF1 Score (Weighted): 0.9546395465861538\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 4\nTraining loss: 0.167468023761897\nValidation loss: 0.1893121540918946\nF1 Score (Weighted): 0.948052395596726\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nEpoch 5\nTraining loss: 0.11332004249725543\nValidation loss: 0.18557060964405536\nF1 Score (Weighted): 0.948052395596726\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Loading and Evaluation","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n\n# Move the model to the specified device (CPU or GPU)\nmodel.to(device)\n\n# Load the fine-tuned weights of the model from the saved file\nmodel.load_state_dict(torch.load('/kaggle/working/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n\n# Evaluate the model on the validation dataset to obtain predictions and true labels\n_, predictions, true_vals = evaluate(dataloader_validation)\n\n# Calculate and print the accuracy for each class based on the predictions and true labels\naccuracy_per_class(predictions, true_vals)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:46.433507Z","iopub.execute_input":"2024-04-02T12:41:46.433896Z","iopub.status.idle":"2024-04-02T12:41:49.805884Z","shell.execute_reply.started":"2024-04-02T12:41:46.433859Z","shell.execute_reply":"2024-04-02T12:41:49.804901Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Phone\nAccuracy: 12/15\n\nClass: Tab\nAccuracy: 15/15\n\nClass: TV\nAccuracy: 15/15\n\nClass: AC\nAccuracy: 15/15\n\nClass: Wash\nAccuracy: 13/15\n\nClass: Fridge\nAccuracy: 14/15\n\nClass: Vacuum\nAccuracy: 13/15\n\nClass: Dish\nAccuracy: 14/15\n\nClass: Micro\nAccuracy: 13/15\n\nClass: Watch\nAccuracy: 15/15\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference with Fine-Tuned Model","metadata":{}},{"cell_type":"code","source":"model.eval()\n# Your input text\ninput_text = \"how to fix my washing machine?\"\n\n# Tokenize and encode the input text\ninputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\ninput_ids = inputs['input_ids'].to(device)\nattention_mask = inputs['attention_mask'].to(device)\n\n# Make predictions\nwith torch.no_grad():\n    output = model(input_ids=input_ids, attention_mask=attention_mask)\n\n# Extract predicted probabilities or class labels\npredicted_probabilities = torch.softmax(output.logits, dim=1).cpu().numpy()\npredicted_class = np.argmax(predicted_probabilities, axis=-1)\n\n# Print the results\nprint(\"Predicted probabilities:\", predicted_probabilities)\nprint(\"Predicted class:\", predicted_class)\nkey_list = list(label_dict.keys())\nval_list = list(label_dict.values())\n \n# print key with val 100\nposition = val_list.index(predicted_class)\nprint(key_list[position])\nkey_list","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:49.807361Z","iopub.execute_input":"2024-04-02T12:41:49.807711Z","iopub.status.idle":"2024-04-02T12:41:49.836717Z","shell.execute_reply.started":"2024-04-02T12:41:49.807680Z","shell.execute_reply":"2024-04-02T12:41:49.835687Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Predicted probabilities: [[0.04512616 0.04308594 0.06931993 0.05246408 0.32251826 0.03305347\n  0.15799254 0.19748718 0.04669596 0.03225644]]\nPredicted class: [4]\nWash\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['Phone',\n 'Tab',\n 'TV',\n 'AC',\n 'Wash',\n 'Fridge',\n 'Vacuum',\n 'Dish',\n 'Micro',\n 'Watch']"},"metadata":{}}]},{"cell_type":"markdown","source":"### After the intent dataset is created from user History, a Hybrid Recommender System leveraging Statistics, Reinforcement Learning and Collaborative Filtering is used to suggest personalized prompt suggestions to the user.","metadata":{}},{"cell_type":"markdown","source":"## User Data Generation\n\n### Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Importing the random module for generating random numbers and performing random sampling\nimport random\n\n# Importing the NumPy library and aliasing it as np\n# NumPy is used for numerical computing and provides support for arrays and mathematical functions\nimport numpy as np\n\n# Importing the matplotlib.pyplot module and aliasing it as plt\n# Matplotlib is a plotting library used to create various types of plots and visualizations\nimport matplotlib.pyplot as plt\n\n# Importing the pandas library and aliasing it as pd\n# Pandas is used for data manipulation and analysis, providing data structures like Series and DataFrame\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:49.838042Z","iopub.execute_input":"2024-04-02T12:41:49.838422Z","iopub.status.idle":"2024-04-02T12:41:49.843137Z","shell.execute_reply.started":"2024-04-02T12:41:49.838385Z","shell.execute_reply":"2024-04-02T12:41:49.842290Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Generating Synthetic Data","metadata":{}},{"cell_type":"code","source":"# Assigning the list of possible labels to the variable test_list\ntest_list = possible_labels\n\n# Printing the original list\nprint(\"Original list is : \" + str(test_list))\n\n# Generating random labels\ny = []\nfor i in range(10000):\n    rand_idx = random.randrange(len(test_list))\n    random_label = test_list[rand_idx]\n    y.append(random_label)\n\n# Encoding labels using LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\n# Generating random time values\ntime = []\nfor i in range(10000):\n    time.append(random.randint(0, 23))\n\n# Generating random user IDs\nuserid = []\nfor i in range(10000):\n    userid.append(random.randint(0, 60))\n\n# Creating a DataFrame with userid, time, query, and reward columns\ndf = pd.DataFrame({'userid': userid, 'time': time, 'query': y})\n\n# Generating random reward values (0 or 1)\nreward = []\nfor i in range(10000):\n    reward.append(random.choice([0,1]))\n\n# Adding the 'reward' column to the DataFrame\ndf['reward'] = reward","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:49.844822Z","iopub.execute_input":"2024-04-02T12:41:49.845105Z","iopub.status.idle":"2024-04-02T12:41:49.932098Z","shell.execute_reply.started":"2024-04-02T12:41:49.845081Z","shell.execute_reply":"2024-04-02T12:41:49.931252Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Original list is : ['Phone' 'Tab' 'TV' 'AC' 'Wash' 'Fridge' 'Vacuum' 'Dish' 'Micro' 'Watch']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"# Printing the original list of possible labels\nprint(\"Original list is : \" + str(test_list))\n\n# Printing the first few rows of the DataFrame\nprint(df.head())\n\n# Printing the shape of the DataFrame (number of rows and columns)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:49.932912Z","iopub.execute_input":"2024-04-02T12:41:49.933178Z","iopub.status.idle":"2024-04-02T12:41:49.940423Z","shell.execute_reply.started":"2024-04-02T12:41:49.933154Z","shell.execute_reply":"2024-04-02T12:41:49.939550Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Original list is : ['Phone' 'Tab' 'TV' 'AC' 'Wash' 'Fridge' 'Vacuum' 'Dish' 'Micro' 'Watch']\n   userid  time  query  reward\n0      38     5      3       0\n1      17     5      7       0\n2      49    21      8       0\n3      46    15      2       0\n4      30    19      8       0\n(10000, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# User Query Analysis","metadata":{}},{"cell_type":"code","source":"# Extracting the 'userid' column from the DataFrame\nuserid=int(input())\n\n# Importing the NumPy library\nimport numpy as np\n\n# Finding unique labels and their frequencies for the specified 'userid'\nunique, frequency = np.unique(df['query'][df['userid']==userid], return_counts = True)\n\n# Sorting indices based on frequencies in descending order\nsorted_indices = np.argsort(frequency)[::-1]\n\n# Getting the top two labels and their frequencies\ntop_labels = unique[sorted_indices[:2]]\ntop_counts = frequency[sorted_indices[:2]]\n\n# Converting label indices to their original values using inverse transform\ntop_labeleng=le.inverse_transform(top_labels)\ntop_labeleng","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:49.941609Z","iopub.execute_input":"2024-04-02T12:41:49.941963Z","iopub.status.idle":"2024-04-02T12:41:54.070072Z","shell.execute_reply.started":"2024-04-02T12:41:49.941921Z","shell.execute_reply":"2024-04-02T12:41:54.069183Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdin","text":" 3\n"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array(['Wash', 'Dish'], dtype='<U6')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Contextual Learner Class\n\n### Class Definition","metadata":{}},{"cell_type":"code","source":"class ContextualLearner:\n    # Constructor to initialize the class\n    # Parameters:\n    #     learnerclass: SGDClassifier (preferred) or SGDRegressor\n    #     rew_vec: array of possible rewards for SGDClassifier and None for SGDRegressor\n    def __init__(self, learnerclass, rew_vec):\n        # Initialize instance variables\n        self.sgd = None\n        self.hist = 50\n        self.arm_sgd = {}\n        self.dataX = {}\n        self.dataY = {}\n        self.rew_vec = rew_vec\n        self.Learner = learnerclass\n\n    # Method to learn from an individual datapoint\n    # Parameters:\n    #     ctx_vector: vector of context values pre-normalized\n    #     arm: action selected as a string\n    #     reward: scalar reward value\n    # Returns:\n    #     status: True or False if learning was successful\n    def train(self, ctx_vector, arm, reward):\n        X = []\n        Y = []\n        if ctx_vector is None or arm is None or reward is None:\n            return False\n        # If the arm classifier doesn't exist\n        if arm not in self.arm_sgd.keys():\n            self.arm_sgd[arm] = self.Learner()\n            self.dataX[arm] = []\n            self.dataY[arm] = []\n        # Get arm classifier and make prediction\n        self.sgd = self.arm_sgd[arm]\n        if len(self.dataX[arm]) > self.hist:\n            X = self.dataX[arm][:-self.hist]\n            Y = self.dataY[arm][:-self.hist]\n        X.append(ctx_vector)\n        X = np.asarray(X)  # .reshape(1, -1)\n        Y.append(reward)  # = [reward]\n        # Fit the data point\n        if self.rew_vec is not None:\n            self.sgd.partial_fit(X, Y, self.rew_vec)\n        else:\n            self.sgd.partial_fit(X, Y)\n        # Add to data vectors\n        self.dataX[arm].append(ctx_vector)\n        self.dataY[arm].append(reward)\n        return True\n\n    # Method to predict reward for an individual datapoint\n    # Parameters:\n    #     ctx_vector: vector of context values pre-normalized\n    #     arm: action selected as a string\n    # Returns:\n    #     reward: scalar reward value\n    def predict(self, ctx_vector, arm):\n        if ctx_vector is None or arm is None:\n            return None\n        # If the arm classifier doesn't exist\n        if arm in self.arm_sgd.keys():\n            # Get arm classifier and make prediction\n            self.sgd = self.arm_sgd[arm]\n            X = ctx_vector\n            X = np.asarray(X).reshape(1, -1)\n            return self.sgd.predict(X)[0]\n        # If nothing found return\n        return 0\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:54.071304Z","iopub.execute_input":"2024-04-02T12:41:54.071662Z","iopub.status.idle":"2024-04-02T12:41:54.084679Z","shell.execute_reply.started":"2024-04-02T12:41:54.071629Z","shell.execute_reply":"2024-04-02T12:41:54.083732Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(df)#printing the dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:54.085870Z","iopub.execute_input":"2024-04-02T12:41:54.086157Z","iopub.status.idle":"2024-04-02T12:41:54.101800Z","shell.execute_reply.started":"2024-04-02T12:41:54.086133Z","shell.execute_reply":"2024-04-02T12:41:54.100945Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"      userid  time  query  reward\n0         38     5      3       0\n1         17     5      7       0\n2         49    21      8       0\n3         46    15      2       0\n4         30    19      8       0\n...      ...   ...    ...     ...\n9995      55    12      1       0\n9996      45    17      0       0\n9997       0     0      1       1\n9998       5     8      7       1\n9999      15     1      0       1\n\n[10000 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training Contextual Bandit Learners\n\n### Importing Libraries","metadata":{}},{"cell_type":"code","source":"# Importing the SGDRegressor and SGDClassifier classes from the sklearn.linear_model module\nfrom sklearn.linear_model import SGDRegressor, SGDClassifier","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:54.103204Z","iopub.execute_input":"2024-04-02T12:41:54.103623Z","iopub.status.idle":"2024-04-02T12:41:54.206434Z","shell.execute_reply.started":"2024-04-02T12:41:54.103582Z","shell.execute_reply":"2024-04-02T12:41:54.205749Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Training Bandit Learners","metadata":{}},{"cell_type":"code","source":"\n# Assuming df is your DataFrame containing user data\n\n# count unique users\nunique_users = df['userid'].unique()\n\n# Define context vector fields\ncontext_vector = ['time']\n\n# Dictionary to hold bandit learners for each user\nuser_bandits = {}\n\n# Loop over unique users\nfor user_id in unique_users:\n    # Filter DataFrame for current user\n    user_df = df[df['userid'] == user_id]\n    \n    # Initialize a new bandit learner for the current user\n    user_bandits[user_id] = ContextualLearner(SGDRegressor, None)\n    \n    # Loop over records for the current user\n    for index, record in user_df.iterrows():\n        # Get context vector\n        ctx_vec = record[context_vector].tolist()\n        # Simple normalization for age\n        ctx_vec[0] = ctx_vec[0] / 100.\n        # Get recommendation - action or arm\n        arm = record['query']\n        # Get reward scalar value - rating given by user\n        rew = record['reward']\n        # Predict reward\n        rew_pred = user_bandits[user_id].predict(ctx_vec, arm)\n        # Train the bandit learner\n        user_bandits[user_id].train(ctx_vec, arm, rew)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:41:54.207346Z","iopub.execute_input":"2024-04-02T12:41:54.207575Z","iopub.status.idle":"2024-04-02T12:42:03.378327Z","shell.execute_reply.started":"2024-04-02T12:41:54.207554Z","shell.execute_reply":"2024-04-02T12:42:03.377422Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Using Trained Bandit Learners\n### Predicting Rewards for Each User at a Specific Time","metadata":{}},{"cell_type":"code","source":"# Now, you can use the trained bandit learners for each user as needed\n# For example, to predict rewards for a specific time for each user:\ntime = int(input(\"Enter time: \"))\nreward_lists = {}  # Dictionary to hold reward lists for each user\n\nfor user_id, bandit in user_bandits.items():\n    # Assuming df is your DataFrame containing user data\n    user_df = df[df['userid'] == user_id]\n    \n    # Initialize reward list for the current user\n    reward_list = []\n    \n    # Loop over records for the current user\n    for index, record in user_df.iterrows():\n        # Get context vector\n        ctx_vec = record[context_vector].tolist()\n        # Simple normalization for age\n        ctx_vec[0] = ctx_vec[0] / 100.\n        # Get recommendation - action or arm\n        arm = record['query']\n        # Predict reward\n        rew_pred = bandit.predict(ctx_vec, arm)\n        reward_list.append(rew_pred)\n    \n    # Store the reward list for the current user\n    reward_lists[user_id] = reward_list\n\n# Now reward_lists dictionary contains reward lists for each user\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:03.379454Z","iopub.execute_input":"2024-04-02T12:42:03.379778Z","iopub.status.idle":"2024-04-02T12:42:14.249692Z","shell.execute_reply.started":"2024-04-02T12:42:03.379751Z","shell.execute_reply":"2024-04-02T12:42:14.248789Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter time:  7\n"}]},{"cell_type":"markdown","source":"## Getting Top Labels for a User\n\n### Function Definition","metadata":{}},{"cell_type":"code","source":"def get_top_labels(user_id, num_labels=2):\n    # Check if the user ID exists in the bandit learners dictionary\n    if user_id in user_bandits:\n        # Get the bandit learner for the specified user\n        bandit = user_bandits[user_id]\n        \n        # Predict rewards for all possible actions\n        rewards = {}\n        num_actions = df['query'].nunique()\n\n        for action in range(num_actions):  # Assuming num_actions is defined somewhere\n            # Create a context vector (here, using default values, modify as needed)\n            ctx_vec = [0.5]  # Placeholder context vector\n            \n            # Predict reward for the current action\n            rew_pred = bandit.predict(ctx_vec, action)\n            rewards[action] = rew_pred\n        \n        # Sort actions based on predicted rewards\n        sorted_actions = sorted(rewards, key=rewards.get, reverse=True)\n        \n        # Get the top labels and their predicted rewards\n        top_labels = [sorted_actions[i] for i in range(min(num_labels, len(sorted_actions)))]\n        top_rewards = [rewards[action] for action in top_labels]\n        \n        return top_labels, top_rewards\n    else:\n        print(\"User ID not found.\")\n        return None, None\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:14.250964Z","iopub.execute_input":"2024-04-02T12:42:14.251713Z","iopub.status.idle":"2024-04-02T12:42:14.258904Z","shell.execute_reply.started":"2024-04-02T12:42:14.251683Z","shell.execute_reply":"2024-04-02T12:42:14.257941Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Example Usage","metadata":{}},{"cell_type":"code","source":"# Example usage: taking user ID input and getting top labels\nuser_id = int(input(\"Enter user ID: \"))\ntop_labels, top_rewards = get_top_labels(user_id)\n\nif top_labels is not None:\n    print(\"Top labels for user {}: {}\".format(user_id, top_labels))\n    print(\"Corresponding rewards:\", top_rewards)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:14.260049Z","iopub.execute_input":"2024-04-02T12:42:14.260296Z","iopub.status.idle":"2024-04-02T12:42:20.098365Z","shell.execute_reply.started":"2024-04-02T12:42:14.260274Z","shell.execute_reply":"2024-04-02T12:42:20.097398Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter user ID:  4\n"},{"name":"stdout","text":"Top labels for user 4: [0, 8]\nCorresponding rewards: [0.08106802524370878, 0.05794403900292082]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Collaborative Filtering Method\n\n### Splitting Data for Training and Testing","metadata":{}},{"cell_type":"code","source":"# Importing the train_test_split function from the sklearn.model_selection module\nfrom sklearn.model_selection import train_test_split\n\n# Splitting the DataFrame 'df' into train and test sets\n# Parameters:\n#     df: DataFrame to be split\n#     test_size: proportion of the dataset to include in the test split (0.30 indicates 30%)\n#     random_state: seed used by the random number generator\nX_train, X_test = train_test_split(df, test_size=0.30, random_state=42)\n\n# Printing the shapes of the train and test sets\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:20.103066Z","iopub.execute_input":"2024-04-02T12:42:20.103370Z","iopub.status.idle":"2024-04-02T12:42:20.111486Z","shell.execute_reply.started":"2024-04-02T12:42:20.103345Z","shell.execute_reply":"2024-04-02T12:42:20.110538Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(7000, 4)\n(3000, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Creating User-Item Matrix","metadata":{}},{"cell_type":"code","source":"# Creating a pivot table from the training data\n# Parameters:\n#     index: Column to use as the index in the pivot table ('userid' in this case)\n#     columns: Column to use as the columns in the pivot table ('query' in this case)\n#     values: Column to use as the values in the pivot table ('time' in this case)\n#     aggfunc: Aggregation function to apply if there are multiple values for a given index/column pair ('mean' in this case)\n#     fillna: Value to replace NaN values with (0 in this case)\nuser_data = X_train.pivot_table(index='userid', columns='query', values='time', aggfunc='mean').fillna(0)\n\n# Displaying the first few rows of the pivot table\nuser_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:20.112542Z","iopub.execute_input":"2024-04-02T12:42:20.112854Z","iopub.status.idle":"2024-04-02T12:42:20.147952Z","shell.execute_reply.started":"2024-04-02T12:42:20.112830Z","shell.execute_reply":"2024-04-02T12:42:20.147076Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"query           0          1          2          3          4          5  \\\nuserid                                                                     \n0       15.375000   8.454545  10.545455  12.000000  10.083333  16.777778   \n1        8.214286   9.916667  10.181818  13.666667   9.200000  12.888889   \n2       11.466667  10.444444  16.066667   8.333333  14.625000  13.647059   \n3        8.833333  10.428571   8.416667  11.875000  12.700000  10.846154   \n4       11.333333   8.200000   7.333333   9.000000   8.500000   8.250000   \n\nquery           6          7          8          9  \nuserid                                              \n0        7.900000  15.250000   8.222222  14.461538  \n1       13.214286  10.700000   9.818182   9.750000  \n2       10.214286  13.875000  12.357143   9.666667  \n3       14.277778  10.285714  12.444444  10.000000  \n4       10.583333  12.285714  10.733333  10.750000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>query</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n    <tr>\n      <th>userid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.375000</td>\n      <td>8.454545</td>\n      <td>10.545455</td>\n      <td>12.000000</td>\n      <td>10.083333</td>\n      <td>16.777778</td>\n      <td>7.900000</td>\n      <td>15.250000</td>\n      <td>8.222222</td>\n      <td>14.461538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.214286</td>\n      <td>9.916667</td>\n      <td>10.181818</td>\n      <td>13.666667</td>\n      <td>9.200000</td>\n      <td>12.888889</td>\n      <td>13.214286</td>\n      <td>10.700000</td>\n      <td>9.818182</td>\n      <td>9.750000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.466667</td>\n      <td>10.444444</td>\n      <td>16.066667</td>\n      <td>8.333333</td>\n      <td>14.625000</td>\n      <td>13.647059</td>\n      <td>10.214286</td>\n      <td>13.875000</td>\n      <td>12.357143</td>\n      <td>9.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.833333</td>\n      <td>10.428571</td>\n      <td>8.416667</td>\n      <td>11.875000</td>\n      <td>12.700000</td>\n      <td>10.846154</td>\n      <td>14.277778</td>\n      <td>10.285714</td>\n      <td>12.444444</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11.333333</td>\n      <td>8.200000</td>\n      <td>7.333333</td>\n      <td>9.000000</td>\n      <td>8.500000</td>\n      <td>8.250000</td>\n      <td>10.583333</td>\n      <td>12.285714</td>\n      <td>10.733333</td>\n      <td>10.750000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Preparing Dummy Train and Test Data","metadata":{}},{"cell_type":"code","source":"# Creating copies of the training and testing datasets\ndummy_train = X_train.copy()\ndummy_test = X_test.copy()\n\n# Transforming time values to binary (0 if > 0 else 1)\ndummy_train['time'] = dummy_train['time'].apply(lambda x: 0 if x > 0 else 1)\ndummy_test['time'] = dummy_test['time'].apply(lambda x: 1 if x > 0 else 0)\n\n# Marking unrated items as 1 for prediction and 0 for evaluation\ndummy_train = dummy_train.pivot_table(index='userid', columns='query', values='time', aggfunc='mean').fillna(1)\ndummy_test = dummy_test.pivot_table(index='userid', columns='query', values='time', aggfunc='mean').fillna(0)\n\n# Displaying the first few rows of the dummy train and test datasets\ndummy_train.head()\ndummy_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:20.149206Z","iopub.execute_input":"2024-04-02T12:42:20.149939Z","iopub.status.idle":"2024-04-02T12:42:21.376551Z","shell.execute_reply.started":"2024-04-02T12:42:20.149905Z","shell.execute_reply":"2024-04-02T12:42:21.375533Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"query          0         1         2    3         4         5    6    7    8  \\\nuserid                                                                         \n0       1.000000  1.000000  1.000000  1.0  1.000000  0.923077  0.8  1.0  1.0   \n1       1.000000  1.000000  1.000000  1.0  1.000000  1.000000  1.0  1.0  1.0   \n2       1.000000  1.000000  1.000000  1.0  0.857143  1.000000  1.0  1.0  0.0   \n3       1.000000  0.888889  0.500000  1.0  1.000000  1.000000  1.0  1.0  1.0   \n4       0.916667  1.000000  0.833333  1.0  1.000000  0.750000  1.0  1.0  1.0   \n\nquery     9  \nuserid       \n0       1.0  \n1       1.0  \n2       1.0  \n3       1.0  \n4       1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>query</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n    <tr>\n      <th>userid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.923077</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.857143</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.000000</td>\n      <td>0.888889</td>\n      <td>0.500000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.916667</td>\n      <td>1.000000</td>\n      <td>0.833333</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.750000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Computing User Similarity Matrix","metadata":{}},{"cell_type":"code","source":"# Importing the cosine_similarity function from the sklearn.metrics.pairwise module\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Computing cosine similarity between users using the user data\nuser_similarity = cosine_similarity(user_data)\n\n# Handling NaN values by replacing them with 0\nuser_similarity[np.isnan(user_similarity)] = 0\n\n# Printing the user similarity matrix and its shape\nprint(\"User Similarity Matrix:\")\nprint(user_similarity)\nprint(\"Shape:\", user_similarity.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:21.377613Z","iopub.execute_input":"2024-04-02T12:42:21.377937Z","iopub.status.idle":"2024-04-02T12:42:21.537601Z","shell.execute_reply.started":"2024-04-02T12:42:21.377911Z","shell.execute_reply":"2024-04-02T12:42:21.536581Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"User Similarity Matrix:\n[[1.         0.95320026 0.95348032 ... 0.9633914  0.90903211 0.97131143]\n [0.95320026 1.         0.95894915 ... 0.97724512 0.93504682 0.98445468]\n [0.95348032 0.95894915 1.         ... 0.97180626 0.93146521 0.97841628]\n ...\n [0.9633914  0.97724512 0.97180626 ... 1.         0.9639072  0.97513513]\n [0.90903211 0.93504682 0.93146521 ... 0.9639072  1.         0.93540072]\n [0.97131143 0.98445468 0.97841628 ... 0.97513513 0.93540072 1.        ]]\nShape: (61, 61)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##  Predicting Ratings","metadata":{}},{"cell_type":"code","source":"# Predict user ratings by dot product of similarity matrix and user-item matrix\nuser_predicted_ratings = np.dot(user_similarity, user_data)\nuser_predicted_ratings\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:21.539006Z","iopub.execute_input":"2024-04-02T12:42:21.540279Z","iopub.status.idle":"2024-04-02T12:42:21.559448Z","shell.execute_reply.started":"2024-04-02T12:42:21.540250Z","shell.execute_reply":"2024-04-02T12:42:21.558583Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[700.40420435, 643.44148028, 683.61330982, 650.20329654,\n        660.39287842, 657.57399215, 649.24663133, 653.86791447,\n        667.22382139, 659.77736817],\n       [710.96065403, 654.98870672, 696.18997277, 662.04174527,\n        671.965631  , 668.16707267, 661.87696198, 664.43177826,\n        679.03027287, 669.9091367 ],\n       [710.75945639, 654.3208316 , 696.23687517, 660.08045119,\n        672.34443029, 667.1097069 , 660.53661069, 664.1765844 ,\n        678.48786762, 668.57618222],\n       [712.2420941 , 656.20450288, 696.43724802, 662.32151454,\n        673.69127775, 668.20614991, 662.82220758, 665.10939312,\n        680.28738123, 670.62193998],\n       [714.90160073, 657.23936813, 697.45870269, 663.27855653,\n        674.15241621, 669.09528009, 663.63282287, 667.19440475,\n        681.70328677, 672.64563372],\n       [717.56369458, 660.85587915, 700.9939619 , 666.15397202,\n        677.7217793 , 671.61911486, 665.86737997, 669.02278495,\n        684.32589711, 675.68399867],\n       [720.96934362, 663.77534118, 705.20401204, 669.85312324,\n        681.42050018, 675.72339908, 670.19767747, 672.94242257,\n        687.52071273, 678.54697972],\n       [709.8309384 , 653.64385427, 694.66519773, 660.14456017,\n        670.31405837, 665.5585041 , 660.5083585 , 663.05848401,\n        678.08378962, 669.02003283],\n       [715.26480418, 657.37007615, 697.78989944, 663.92657951,\n        675.19059545, 670.47808678, 663.71319654, 666.92113166,\n        681.96455991, 673.0315423 ],\n       [719.78306763, 662.17868905, 703.55589458, 668.07265113,\n        679.3017098 , 673.52593622, 668.22333326, 670.71031417,\n        686.35309735, 676.35297968],\n       [713.31197478, 655.32572229, 697.49179774, 661.71701441,\n        672.39114879, 668.09111577, 662.45829343, 664.890252  ,\n        680.21705192, 670.33518832],\n       [707.422675  , 651.67201487, 693.96818643, 658.81062231,\n        669.31278146, 665.77530713, 658.23863013, 661.38453146,\n        676.23973407, 666.89790985],\n       [713.46525819, 655.74931034, 697.94055229, 662.91454883,\n        674.09956507, 669.65356494, 663.17045325, 665.77729263,\n        680.86266413, 671.10482135],\n       [688.74041037, 634.63967434, 675.21387048, 639.88170485,\n        651.63259563, 643.87104772, 641.66838795, 643.72439321,\n        656.69576304, 646.68837804],\n       [718.12739844, 661.10991775, 700.76220936, 666.13855732,\n        678.01885294, 672.46707414, 665.94905862, 669.24943777,\n        684.85727335, 675.91791931],\n       [705.73460809, 650.78971299, 690.26204909, 655.93073646,\n        668.20263321, 662.04004006, 655.06279995, 658.85671623,\n        673.99676896, 664.36984731],\n       [714.92574501, 658.67740881, 699.91029202, 663.93400887,\n        675.27145375, 670.59596986, 664.31747803, 667.91655104,\n        682.37861694, 672.80839617],\n       [713.30965854, 656.20680521, 695.44402506, 661.85675229,\n        672.82188866, 667.63569849, 661.68110059, 664.48380389,\n        679.65036632, 671.90288288],\n       [705.48623627, 648.8533328 , 689.79513798, 654.924319  ,\n        667.69394264, 660.23411686, 655.34870043, 659.00918375,\n        672.25513934, 663.35988506],\n       [710.80972709, 654.90181856, 696.42241535, 660.69259287,\n        671.89825716, 666.8495182 , 661.81451097, 663.61966799,\n        678.59941318, 668.5545363 ],\n       [700.85575272, 645.21488954, 684.66775657, 650.82996204,\n        660.36500848, 658.06305199, 650.02214789, 654.00217096,\n        670.02873186, 660.01068894],\n       [714.2162984 , 657.56533492, 696.40200177, 661.94664757,\n        673.48532439, 668.01931444, 662.0893238 , 665.19577051,\n        680.41168714, 671.64656363],\n       [706.69068142, 651.70959429, 689.59997535, 655.66630246,\n        667.74932916, 663.27282005, 655.78947144, 659.19936399,\n        674.50058429, 665.53576154],\n       [702.29082403, 647.57494843, 689.25319113, 654.05308078,\n        664.65299582, 661.07652226, 653.58671317, 657.18569712,\n        670.83110199, 661.78153626],\n       [709.18610109, 652.64920375, 693.07381515, 659.23869621,\n        668.01326231, 664.9858874 , 658.62368337, 661.50434765,\n        676.4351095 , 668.20253313],\n       [715.53810442, 658.85023783, 700.88017535, 665.11029396,\n        677.0029548 , 670.96759756, 665.75295233, 668.36725782,\n        682.94026006, 672.91403616],\n       [706.86217774, 650.98012012, 691.96713001, 657.79333938,\n        667.6314571 , 664.77241256, 657.69532173, 661.47825172,\n        675.55230923, 666.29682314],\n       [710.6055125 , 653.08047579, 693.49353472, 658.59027631,\n        669.60279262, 665.69622584, 659.33734041, 662.20203876,\n        677.81614134, 667.4399194 ],\n       [695.95847436, 638.52789355, 680.68121596, 646.24013561,\n        655.27112989, 651.14511006, 646.2406093 , 647.61453245,\n        663.42738354, 653.50243019],\n       [718.80472984, 661.8129384 , 701.96612464, 667.51824282,\n        678.38200412, 672.80981982, 667.27385724, 670.36809826,\n        685.91047687, 676.03429443],\n       [708.43024486, 653.04642565, 691.65221642, 657.64690707,\n        669.53588634, 664.83819805, 658.15512525, 660.39753642,\n        676.04994495, 667.4439427 ],\n       [705.89666464, 648.99371865, 689.14397011, 655.40245838,\n        664.91882533, 660.77513103, 655.39015105, 658.95640345,\n        673.90898924, 663.77169978],\n       [713.93568613, 657.8743474 , 698.84923488, 663.52386924,\n        674.76935643, 669.66873152, 664.07883229, 666.84505693,\n        682.40099612, 672.18986398],\n       [713.25601407, 656.69143141, 697.01048316, 662.80812377,\n        673.30716254, 667.70872237, 661.73790088, 664.34643261,\n        680.33295863, 671.54204142],\n       [717.59097391, 660.29851477, 700.47336086, 665.7453815 ,\n        677.54490419, 671.77185661, 665.80941329, 669.160631  ,\n        684.82717126, 674.97913769],\n       [712.38247287, 656.25281301, 695.82034232, 661.43790283,\n        673.58217032, 666.99162655, 661.51133455, 665.53027398,\n        679.36838471, 670.67355946],\n       [706.85498622, 649.9888396 , 690.98597579, 655.29517167,\n        666.97934113, 659.69621252, 656.05703641, 658.15574274,\n        673.04426666, 663.85294961],\n       [707.42087629, 650.78668804, 691.24643618, 658.15714312,\n        668.72592631, 664.2006222 , 657.24473055, 660.31280122,\n        674.65057285, 666.78252527],\n       [706.14197576, 648.90749854, 688.2559181 , 654.04997887,\n        665.56615647, 659.44918088, 654.87324178, 658.45771417,\n        672.0069049 , 664.08293207],\n       [704.1582458 , 648.30423526, 690.09591841, 654.75251211,\n        665.39595997, 662.73156913, 654.90051899, 658.5495304 ,\n        672.78853217, 663.97464901],\n       [716.44984944, 659.4913119 , 700.83646578, 665.37277051,\n        676.52065181, 671.01737692, 665.36267164, 668.16190132,\n        683.99176555, 674.34288394],\n       [711.46524394, 654.84454382, 695.2862437 , 661.25073244,\n        670.72662618, 666.5984535 , 659.8884814 , 662.93203144,\n        679.08893122, 669.38951342],\n       [701.71397048, 645.20880419, 686.1655428 , 651.75662676,\n        663.21711198, 658.21012492, 651.95842341, 654.77119871,\n        670.14941622, 658.74853156],\n       [712.5360248 , 657.20513954, 696.70411541, 662.30674352,\n        674.25229391, 669.45329256, 662.15192295, 665.61026503,\n        680.13935606, 671.63348878],\n       [720.30411299, 662.1549311 , 703.37361418, 668.04343832,\n        679.35214933, 674.11744282, 668.50053979, 671.81835123,\n        686.63725057, 677.12076517],\n       [717.20682447, 659.93499667, 699.69486958, 665.08519963,\n        675.9862267 , 670.58920075, 664.93236362, 667.84806979,\n        683.29253175, 674.24919405],\n       [715.82865151, 658.36539386, 699.98751876, 665.45186088,\n        675.8065537 , 670.29879493, 664.8251909 , 668.07886758,\n        682.20404525, 673.52613108],\n       [717.63004603, 660.30571965, 701.29886773, 666.81057793,\n        677.00767523, 671.52727757, 666.44689297, 669.47388044,\n        684.31023798, 675.50288556],\n       [712.45729043, 656.91480648, 696.95966693, 662.33781955,\n        673.28402696, 668.01404399, 661.85106866, 664.30345909,\n        680.38591212, 670.20139301],\n       [714.54603315, 657.56058309, 696.3119355 , 662.64726221,\n        673.96103883, 668.8720644 , 662.21459218, 665.74517964,\n        681.44242653, 672.25610834],\n       [708.50965664, 653.17336474, 694.08478296, 659.48427944,\n        670.55596811, 665.58996498, 659.38643738, 661.65499353,\n        676.25605467, 668.43545116],\n       [709.72279955, 652.3763432 , 693.76328337, 658.54720678,\n        670.63671516, 663.58429519, 659.27664008, 662.77540275,\n        676.0897514 , 666.90764473],\n       [701.86338925, 644.7614218 , 684.5536132 , 650.77888696,\n        660.82246886, 658.02583548, 649.75878669, 653.73139293,\n        669.04995245, 661.05894035],\n       [708.46049063, 652.78665313, 693.08571847, 658.94686349,\n        668.29729633, 663.583794  , 658.29319405, 661.00918015,\n        675.5028932 , 667.55200588],\n       [715.59759123, 658.20686964, 698.63745056, 663.60939003,\n        675.73486611, 669.06114642, 664.03706651, 666.74979704,\n        681.48078483, 672.11293985],\n       [706.32191579, 650.3616884 , 691.38255973, 657.12978097,\n        668.03753943, 664.26696277, 656.82840668, 659.39068022,\n        673.85782816, 666.17626521],\n       [709.40436459, 654.07195185, 695.22227046, 659.93857067,\n        670.62644527, 665.07467646, 659.11803214, 662.18796403,\n        676.86945196, 667.86920875],\n       [711.36000333, 654.48944807, 696.6407246 , 660.90053375,\n        671.30156448, 665.39604479, 660.8406768 , 663.1850666 ,\n        678.30143126, 668.64889314],\n       [717.34961728, 660.94385348, 701.05584015, 666.10464318,\n        677.57126168, 672.1014377 , 666.40881594, 669.60532205,\n        683.76745013, 675.31224495],\n       [701.25459499, 646.06324887, 683.29899799, 650.0324628 ,\n        662.05985408, 655.2533068 , 650.18406831, 652.08203497,\n        668.38595563, 659.56109208],\n       [716.56991304, 658.97904501, 701.30226164, 666.42268238,\n        676.83891407, 672.16675855, 665.78413632, 669.17324257,\n        683.68622789, 674.33218035]])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Finalizing Predictions","metadata":{}},{"cell_type":"code","source":"# Multiply predicted ratings with the dummy train data\nuser_final_ratings = np.multiply(user_predicted_ratings, dummy_train)\nuser_final_ratings.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:21.560604Z","iopub.execute_input":"2024-04-02T12:42:21.560940Z","iopub.status.idle":"2024-04-02T12:42:21.577212Z","shell.execute_reply.started":"2024-04-02T12:42:21.560907Z","shell.execute_reply":"2024-04-02T12:42:21.576294Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"query            0          1           2          3          4    5    6  \\\nuserid                                                                      \n0         0.000000  58.494680    0.000000  72.244811  55.032740  0.0  0.0   \n1       152.348712   0.000000   63.289998   0.000000  44.797709  0.0  0.0   \n2        47.383964  72.702315    0.000000   0.000000   0.000000  0.0  0.0   \n3       118.707016   0.000000    0.000000   0.000000   0.000000  0.0  0.0   \n4        79.433511   0.000000  464.972468   0.000000   0.000000  0.0  0.0   \n\nquery           7          8           9  \nuserid                                    \n0       54.488993  74.135980   50.752105  \n1        0.000000  61.730025    0.000000  \n2       41.511037   0.000000   44.571745  \n3        0.000000  37.793743   83.827742  \n4        0.000000  90.893772  112.107606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>query</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n    <tr>\n      <th>userid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>58.494680</td>\n      <td>0.000000</td>\n      <td>72.244811</td>\n      <td>55.032740</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>54.488993</td>\n      <td>74.135980</td>\n      <td>50.752105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>152.348712</td>\n      <td>0.000000</td>\n      <td>63.289998</td>\n      <td>0.000000</td>\n      <td>44.797709</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>61.730025</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47.383964</td>\n      <td>72.702315</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>41.511037</td>\n      <td>0.000000</td>\n      <td>44.571745</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>118.707016</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>37.793743</td>\n      <td>83.827742</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>79.433511</td>\n      <td>0.000000</td>\n      <td>464.972468</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>90.893772</td>\n      <td>112.107606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Example: Top recommendations for a user\n","metadata":{}},{"cell_type":"code","source":"# Specify the user ID for which recommendations are to be generated\nuser_id = 42\n\n# Get the top recommendations for the specified user\ntop_recommendations = user_final_ratings.iloc[user_id].sort_values(ascending=False)[:5]\n\n# Print the top recommendations for the user\nprint(\"Top recommendations for user\", user_id, \":\", top_recommendations)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T12:42:21.578276Z","iopub.execute_input":"2024-04-02T12:42:21.578566Z","iopub.status.idle":"2024-04-02T12:42:21.586785Z","shell.execute_reply.started":"2024-04-02T12:42:21.578543Z","shell.execute_reply":"2024-04-02T12:42:21.585887Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Top recommendations for user 42 : query\n3    59.250602\n7    43.651413\n1     0.000000\n0     0.000000\n4     0.000000\nName: 42, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### *Although, the label classifier requires GPU to train, the core recommender is very lightweight, and  can be run on CPU.*","metadata":{}},{"cell_type":"code","source":"# Get the index of the top recommendation\ntop_label_index = top_recommendations.index[0]\n\n# Print the index of the top recommendation\nprint(top_label_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:08:57.633413Z","iopub.execute_input":"2024-04-02T13:08:57.633780Z","iopub.status.idle":"2024-04-02T13:08:57.639985Z","shell.execute_reply.started":"2024-04-02T13:08:57.633751Z","shell.execute_reply":"2024-04-02T13:08:57.639125Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"# Filter the DataFrame 'data' to include only rows where the 'label' column matches the top label index\nfiltered_df = data[data['label'] == top_label_index]","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:16:13.307322Z","iopub.execute_input":"2024-04-02T13:16:13.308103Z","iopub.status.idle":"2024-04-02T13:16:13.313397Z","shell.execute_reply.started":"2024-04-02T13:16:13.308069Z","shell.execute_reply":"2024-04-02T13:16:13.312343Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Randomly select a recommendation from the filtered DataFrame\nrecommendation = filtered_df.sample(n=1)['Input'].iloc[0]\n\n# Print the selected recommendation\nprint(recommendation)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T13:16:15.197075Z","iopub.execute_input":"2024-04-02T13:16:15.198124Z","iopub.status.idle":"2024-04-02T13:16:15.204148Z","shell.execute_reply.started":"2024-04-02T13:16:15.198080Z","shell.execute_reply":"2024-04-02T13:16:15.203028Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Set a schedule for the AC to turn off at 9 PM.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### **Future Plans**: We plan to add full device management capabilities to our chatbot, and not just stop at personalized recommendations. We tinkered with integration of NodeRED with out chatbot, and saw some promising possibilties. As our backbone LLMs are very powerful, if given more time, we would love to add full device management capabilities to our system. ","metadata":{}}]}