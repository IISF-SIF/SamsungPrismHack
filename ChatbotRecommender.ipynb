{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7806407,"sourceType":"datasetVersion","datasetId":4571626}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm transformers torch\nimport pandas as pd\nimport torch\nfrom tqdm.notebook import tqdm\n\nfrom transformers import BertTokenizer\nfrom torch.utils.data import TensorDataset\n\nfrom transformers import BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:02.660731Z","iopub.execute_input":"2024-03-15T18:05:02.661427Z","iopub.status.idle":"2024-03-15T18:05:14.936825Z","shell.execute_reply.started":"2024-03-15T18:05:02.661398Z","shell.execute_reply":"2024-03-15T18:05:14.935642Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/samsungrecommend/RecommenderSamsungDevice - Sheet1.csv')\ndf.head()\ndf['Query'].value_counts()\npossible_labels = df.Query.unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:29.377201Z","iopub.execute_input":"2024-03-15T18:05:29.377970Z","iopub.status.idle":"2024-03-15T18:05:29.418784Z","shell.execute_reply.started":"2024-03-15T18:05:29.377910Z","shell.execute_reply":"2024-03-15T18:05:29.417957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"label_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:35.849605Z","iopub.execute_input":"2024-03-15T18:05:35.850256Z","iopub.status.idle":"2024-03-15T18:05:35.858225Z","shell.execute_reply.started":"2024-03-15T18:05:35.850226Z","shell.execute_reply":"2024-03-15T18:05:35.857312Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'Phone': 0,\n 'Tab': 1,\n 'TV': 2,\n 'AC': 3,\n 'Wash': 4,\n 'Fridge': 5,\n 'Vacuum': 6,\n 'Dish': 7,\n 'Micro': 8,\n 'Watch': 9}"},"metadata":{}}]},{"cell_type":"code","source":"df['label'] = df.Query.replace(label_dict)\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(df.index.values, \n                                                  df.label.values, \n                                                  test_size=0.15, \n                                                  random_state=42, \n                                                  stratify=df.label.values)\n\ndf['data_type'] = ['not_set']*df.shape[0]\n\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'\n\ndf.groupby(['Query', 'label', 'data_type']).count()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:38.609552Z","iopub.execute_input":"2024-03-15T18:05:38.609886Z","iopub.status.idle":"2024-03-15T18:05:39.274824Z","shell.execute_reply.started":"2024-03-15T18:05:38.609862Z","shell.execute_reply":"2024-03-15T18:05:39.273884Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/4262829081.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df['label'] = df.Query.replace(label_dict)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                        Input\nQuery  label data_type       \nAC     3     train         85\n             val           15\nDish   7     train         85\n             val           15\nFridge 5     train         85\n             val           15\nMicro  8     train         85\n             val           15\nPhone  0     train         85\n             val           15\nTV     2     train         85\n             val           15\nTab    1     train         85\n             val           15\nVacuum 6     train         85\n             val           15\nWash   4     train         85\n             val           15\nWatch  9     train         85\n             val           15","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Input</th>\n    </tr>\n    <tr>\n      <th>Query</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">AC</th>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Dish</th>\n      <th rowspan=\"2\" valign=\"top\">7</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Fridge</th>\n      <th rowspan=\"2\" valign=\"top\">5</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Micro</th>\n      <th rowspan=\"2\" valign=\"top\">8</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Phone</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">TV</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Tab</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Vacuum</th>\n      <th rowspan=\"2\" valign=\"top\">6</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Wash</th>\n      <th rowspan=\"2\" valign=\"top\">4</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Watch</th>\n      <th rowspan=\"2\" valign=\"top\">9</th>\n      <th>train</th>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n                                          do_lower_case=True)\n                                          \nencoded_data_train = tokenizer.batch_encode_plus(\n    df[df.data_type=='train'].Input.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\nencoded_data_val = tokenizer.batch_encode_plus(\n    df[df.data_type=='val'].Input.values, \n    add_special_tokens=True, \n    return_attention_mask=True, \n    pad_to_max_length=True, \n    max_length=256, \n    return_tensors='pt'\n)\n\n\ninput_ids_train = encoded_data_train['input_ids']\nattention_masks_train = encoded_data_train['attention_mask']\nlabels_train = torch.tensor(df[df.data_type=='train'].label.values)\n\ninput_ids_val = encoded_data_val['input_ids']\nattention_masks_val = encoded_data_val['attention_mask']\nlabels_val = torch.tensor(df[df.data_type=='val'].label.values)\n\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:41.829110Z","iopub.execute_input":"2024-03-15T18:05:41.830336Z","iopub.status.idle":"2024-03-15T18:05:43.977224Z","shell.execute_reply.started":"2024-03-15T18:05:41.830298Z","shell.execute_reply":"2024-03-15T18:05:43.976379Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acfb4ab9cbbc480e9620abdce2215120"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69247efff7db47d4bcba45a1a183c8f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3566746c1c64d41b969523e0bce15e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4616a3b2a1804f2f9035ca299e427559"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:05:57.608662Z","iopub.execute_input":"2024-03-15T18:05:57.609067Z","iopub.status.idle":"2024-03-15T18:05:59.579471Z","shell.execute_reply.started":"2024-03-15T18:05:57.609037Z","shell.execute_reply":"2024-03-15T18:05:59.578712Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5efbea5e103f40bba6b085ed68617858"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 3\n\ndataloader_train = DataLoader(dataset_train, \n                              sampler=RandomSampler(dataset_train), \n                              batch_size=batch_size)\n\ndataloader_validation = DataLoader(dataset_val, \n                                   sampler=SequentialSampler(dataset_val), \n                                   batch_size=batch_size)\nfrom transformers import AdamW, get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:02.276438Z","iopub.execute_input":"2024-03-15T18:06:02.277274Z","iopub.status.idle":"2024-03-15T18:06:02.288438Z","shell.execute_reply.started":"2024-03-15T18:06:02.277236Z","shell.execute_reply":"2024-03-15T18:06:02.287472Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr=1e-5, \n                  eps=1e-8)\n\n                  \nepochs = 5\n\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=0,\n                                            num_training_steps=len(dataloader_train)*epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:12.549506Z","iopub.execute_input":"2024-03-15T18:06:12.550255Z","iopub.status.idle":"2024-03-15T18:06:12.561286Z","shell.execute_reply.started":"2024-03-15T18:06:12.550222Z","shell.execute_reply":"2024-03-15T18:06:12.560299Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef f1_score_func(preds, labels):\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, preds_flat, average='weighted')\n\ndef accuracy_per_class(preds, labels):\n    label_dict_inverse = {v: k for k, v in label_dict.items()}\n    \n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n\n    for label in np.unique(labels_flat):\n        y_preds = preds_flat[labels_flat==label]\n        y_true = labels_flat[labels_flat==label]\n        print(f'Class: {label_dict_inverse[label]}')\n        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:21.744760Z","iopub.execute_input":"2024-03-15T18:06:21.745141Z","iopub.status.idle":"2024-03-15T18:06:21.752551Z","shell.execute_reply.started":"2024-03-15T18:06:21.745113Z","shell.execute_reply":"2024-03-15T18:06:21.751603Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import random\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:27.536032Z","iopub.execute_input":"2024-03-15T18:06:27.536691Z","iopub.status.idle":"2024-03-15T18:06:27.815896Z","shell.execute_reply.started":"2024-03-15T18:06:27.536660Z","shell.execute_reply":"2024-03-15T18:06:27.814969Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(dataloader_val):\n\n    model.eval()\n    \n    loss_val_total = 0\n    predictions, true_vals = [], []\n    \n    for batch in dataloader_val:\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }\n\n        with torch.no_grad():        \n            outputs = model(**inputs)\n            \n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs['labels'].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n    \n    loss_val_avg = loss_val_total/len(dataloader_val) \n    \n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n            \n    return loss_val_avg, predictions, true_vals","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:31.792195Z","iopub.execute_input":"2024-03-15T18:06:31.792932Z","iopub.status.idle":"2024-03-15T18:06:31.801202Z","shell.execute_reply.started":"2024-03-15T18:06:31.792899Z","shell.execute_reply":"2024-03-15T18:06:31.800218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(1, epochs+1)):\n    \n    model.train()\n    \n    loss_train_total = 0\n\n    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n    for batch in progress_bar:\n\n        model.zero_grad()\n        \n        batch = tuple(b.to(device) for b in batch)\n        \n        inputs = {'input_ids':      batch[0],\n                  'attention_mask': batch[1],\n                  'labels':         batch[2],\n                 }       \n\n        outputs = model(**inputs)\n        \n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n        \n        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n         \n        \n    torch.save(model.state_dict(), f'/kaggle/working/finetuned_BERT_epoch_{epoch}.model')\n        \n    tqdm.write(f'\\nEpoch {epoch}')\n    \n    loss_train_avg = loss_train_total/len(dataloader_train)            \n    tqdm.write(f'Training loss: {loss_train_avg}')\n    \n    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n    val_f1 = f1_score_func(predictions, true_vals)\n    tqdm.write(f'Validation loss: {val_loss}')\n    tqdm.write(f'F1 Score (Weighted): {val_f1}')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:06:37.963211Z","iopub.execute_input":"2024-03-15T18:06:37.963587Z","iopub.status.idle":"2024-03-15T18:09:18.203100Z","shell.execute_reply.started":"2024-03-15T18:06:37.963553Z","shell.execute_reply":"2024-03-15T18:09:18.202181Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9e8e2fab734b529b7b39f4b2629101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f1d7e7fae64ecc8c25f3368069a8c6"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1\nTraining loss: 2.01882696823335\nValidation loss: 1.2371776461601258\nF1 Score (Weighted): 0.8592444390998341\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"850a3fe2b55448a4bb03d415cdfdca33"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 2\nTraining loss: 0.7884056737620226\nValidation loss: 0.3448184570670128\nF1 Score (Weighted): 0.9536438755904828\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4eb737613c24b218894229fc6b87018"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 3\nTraining loss: 0.27508006706623966\nValidation loss: 0.21254636481404304\nF1 Score (Weighted): 0.9675292185839853\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbd2cb80a5c42e4a8b8d7b1a3e1c859"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 4\nTraining loss: 0.14525881774303778\nValidation loss: 0.18516794476658105\nF1 Score (Weighted): 0.9669772089238161\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5:   0%|          | 0/284 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ede1602c314c3da7586f9f20ddbf92"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 5\nTraining loss: 0.10277595595968231\nValidation loss: 0.18174629237502812\nF1 Score (Weighted): 0.9667939244663383\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels=len(label_dict),\n                                                      output_attentions=False,\n                                                      output_hidden_states=False)\n\nmodel.to(device)\n\nmodel.load_state_dict(torch.load('/kaggle/working/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n\n_, predictions, true_vals = evaluate(dataloader_validation)\naccuracy_per_class(predictions, true_vals)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:09:18.204749Z","iopub.execute_input":"2024-03-15T18:09:18.205063Z","iopub.status.idle":"2024-03-15T18:09:20.473892Z","shell.execute_reply.started":"2024-03-15T18:09:18.205039Z","shell.execute_reply":"2024-03-15T18:09:20.472632Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Class: Phone\nAccuracy: 12/15\n\nClass: Tab\nAccuracy: 15/15\n\nClass: TV\nAccuracy: 15/15\n\nClass: AC\nAccuracy: 15/15\n\nClass: Wash\nAccuracy: 14/15\n\nClass: Fridge\nAccuracy: 13/15\n\nClass: Vacuum\nAccuracy: 14/15\n\nClass: Dish\nAccuracy: 13/15\n\nClass: Micro\nAccuracy: 5/15\n\nClass: Watch\nAccuracy: 14/15\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\n# Your input text\ninput_text = \"how to fix my washing machine?\"\n\n# Tokenize and encode the input text\ninputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\ninput_ids = inputs['input_ids'].to(device)\nattention_mask = inputs['attention_mask'].to(device)\n\n# Make predictions\nwith torch.no_grad():\n    output = model(input_ids=input_ids, attention_mask=attention_mask)\n\n# Extract predicted probabilities or class labels\npredicted_probabilities = torch.softmax(output.logits, dim=1).cpu().numpy()\npredicted_class = np.argmax(predicted_probabilities, axis=-1)\n\n# Print the results\nprint(\"Predicted probabilities:\", predicted_probabilities)\nprint(\"Predicted class:\", predicted_class)\nkey_list = list(label_dict.keys())\nval_list = list(label_dict.values())\n \n# print key with val 100\nposition = val_list.index(predicted_class)\nprint(key_list[position])\nkey_list\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:09:20.475265Z","iopub.execute_input":"2024-03-15T18:09:20.475625Z","iopub.status.idle":"2024-03-15T18:09:20.502618Z","shell.execute_reply.started":"2024-03-15T18:09:20.475589Z","shell.execute_reply":"2024-03-15T18:09:20.501760Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Predicted probabilities: [[0.05097049 0.02972494 0.04694759 0.05964031 0.5591765  0.0631689\n  0.04463558 0.07176366 0.02649357 0.04747843]]\nPredicted class: [4]\nWash\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['Phone',\n 'Tab',\n 'TV',\n 'AC',\n 'Wash',\n 'Fridge',\n 'Vacuum',\n 'Dish',\n 'Micro',\n 'Watch']"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\ntest_list = possible_labels\n\n# printing original list\nprint(\"Original list is : \" + str(test_list))\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\ny=[]\nfor i in range(10000):\n  rand_idx = random.randrange(len(test_list))\n  random_label = test_list[rand_idx]\n  y.append(random_label)\ny\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\ny\ntime=[]\nfor i in range(10000):\n  time.append(random.randint(0, 23))\nuserid=[]\nfor i in range(10000):\n  userid.append(random.randint(0, 60))\ndf=pd.DataFrame({'userid': userid, 'time': time, 'query': y})\n\n\ndf.shape\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:19:14.354753Z","iopub.execute_input":"2024-03-15T18:19:14.355614Z","iopub.status.idle":"2024-03-15T18:19:14.432550Z","shell.execute_reply.started":"2024-03-15T18:19:14.355579Z","shell.execute_reply":"2024-03-15T18:19:14.431683Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Original list is : ['Phone' 'Tab' 'TV' 'AC' 'Wash' 'Fridge' 'Vacuum' 'Dish' 'Micro' 'Watch']\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(10000, 3)"},"metadata":{}}]},{"cell_type":"code","source":"reward=[]\nfor i in range(10000):\n  reward.append(random.choice([0,1]))\ndf['reward']=reward","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:33:37.132511Z","iopub.execute_input":"2024-03-15T18:33:37.132987Z","iopub.status.idle":"2024-03-15T18:33:37.154958Z","shell.execute_reply.started":"2024-03-15T18:33:37.132954Z","shell.execute_reply":"2024-03-15T18:33:37.153999Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:33:43.318407Z","iopub.execute_input":"2024-03-15T18:33:43.318770Z","iopub.status.idle":"2024-03-15T18:33:43.327703Z","shell.execute_reply.started":"2024-03-15T18:33:43.318742Z","shell.execute_reply":"2024-03-15T18:33:43.326498Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"      userid  time  query  reward\n0         38     5      3       1\n1         17     5      7       1\n2         49    21      8       0\n3         46    15      2       0\n4         30    19      8       0\n...      ...   ...    ...     ...\n9995      55    12      1       0\n9996      45    17      0       1\n9997       0     0      1       0\n9998       5     8      7       1\n9999      15     1      0       1\n\n[10000 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"df['userid']\n\nuserid=int(input())\nimport numpy as np\nunique, frequency = np.unique(df['query'][df['userid']==userid], return_counts = True)\nunique\nfrequency\nunique\n# Sort indices based on counts  in descending order\nsorted_indices = np.argsort(frequency)[::-1]\n\n# Get the top two labels and their frequencies\ntop_labels = unique[sorted_indices[:2]]\ntop_counts = frequency[sorted_indices[:2]]\ntop_labels\ntop_labeleng=le.inverse_transform(top_labels)\ntop_labeleng","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:25:16.156737Z","iopub.execute_input":"2024-03-15T18:25:16.157671Z","iopub.status.idle":"2024-03-15T18:25:18.699449Z","shell.execute_reply.started":"2024-03-15T18:25:16.157637Z","shell.execute_reply":"2024-03-15T18:25:18.698493Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdin","text":" 4\n"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"array(['Wash', 'AC'], dtype='<U6')"},"metadata":{}}]},{"cell_type":"code","source":"import random\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:27:02.506727Z","iopub.execute_input":"2024-03-15T18:27:02.507138Z","iopub.status.idle":"2024-03-15T18:27:02.512028Z","shell.execute_reply.started":"2024-03-15T18:27:02.507110Z","shell.execute_reply":"2024-03-15T18:27:02.511051Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class ContextualLearner:\n  # define the initial parameters when initializing class\n  # parameters:\n  #     learnerclass = SGDClassifier (preferred) or SGDRegressor\n  #     rew_vec = array of possible rewards  for SGDClassifier and None for SGDRegressor\n  def __init__(self, learnerclass, rew_vec):\n    self.sgd = None\n    self.hist = 50\n    self.arm_sgd = {}\n    self.dataX = {}\n    self.dataY = {}\n    self.rew_vec = rew_vec\n    self.Learner = learnerclass\n\n  # learn from an individual datapoint\n  # parameters:\n  #     ctx_vector = vector of context values pre normalized\n  #     arm = action selected as a string\n  #     reward = scalar reward value\n  # returns:\n  #     status = True or False if learning was successful\n  def train(self, ctx_vector, arm, reward):\n    X = []\n    Y = []\n    if ctx_vector is None or arm is None or reward is None:\n      return False\n    # if the arm classifier doesn't exist\n    if arm not in self.arm_sgd.keys():\n      self.arm_sgd[arm] = self.Learner()\n      self.dataX[arm] = []\n      self.dataY[arm] = []\n    # get arm classifier and make prediction\n    self.sgd = self.arm_sgd[arm]\n    if len(self.dataX[arm]) > self.hist:\n      X = self.dataX[arm][:-self.hist]\n      Y = self.dataY[arm][:-self.hist]\n    X.append(ctx_vector)\n    X = np.asarray(X) #.reshape(1, -1)\n    Y.append(reward) #= [reward]\n    # fit the data point\n    if self.rew_vec is not None:\n      self.sgd.partial_fit(X, Y, self.rew_vec)\n    else:\n      self.sgd.partial_fit(X, Y)\n    # add to data vectors\n    self.dataX[arm].append(ctx_vector)\n    self.dataY[arm].append(reward)\n    return True\n\n  # predict reward for an individual datapoint\n  # parameters:\n  #     ctx_vector = vector of context values pre normalized\n  #     arm = action selected as a string\n  # returns:\n  #     reward = scalar reward value\n  def predict(self, ctx_vector, arm):\n    if ctx_vector is None or arm is None:\n      return None\n    # if the arm classifier doesn't exist\n    if arm in self.arm_sgd.keys():\n      # get arm classifier and make prediction\n      self.sgd = self.arm_sgd[arm]\n      X = ctx_vector\n      X = np.asarray(X).reshape(1, -1)\n      return self.sgd.predict(X)[0]\n    # if nothing found return\n    return 0","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:27:24.472362Z","iopub.execute_input":"2024-03-15T18:27:24.473140Z","iopub.status.idle":"2024-03-15T18:27:24.485293Z","shell.execute_reply.started":"2024-03-15T18:27:24.473108Z","shell.execute_reply":"2024-03-15T18:27:24.484329Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:33:21.945284Z","iopub.execute_input":"2024-03-15T18:33:21.945913Z","iopub.status.idle":"2024-03-15T18:33:21.968034Z","shell.execute_reply.started":"2024-03-15T18:33:21.945884Z","shell.execute_reply":"2024-03-15T18:33:21.967126Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:32:12.356558Z","iopub.execute_input":"2024-03-15T18:32:12.357290Z","iopub.status.idle":"2024-03-15T18:32:12.365078Z","shell.execute_reply.started":"2024-03-15T18:32:12.357249Z","shell.execute_reply":"2024-03-15T18:32:12.363997Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"      userid  time  query  reward\n0         38     5      3       0\n1         17     5      7       0\n2         49    21      8       0\n3         46    15      2       0\n4         30    19      8       0\n...      ...   ...    ...     ...\n9995      55    12      1       0\n9996      45    17      0       0\n9997       0     0      1       1\n9998       5     8      7       1\n9999      15     1      0       1\n\n[10000 rows x 4 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor, SGDClassifier\n\n# Assuming df is your DataFrame containing user data\n\n# count unique users\nunique_users = df['userid'].unique()\n\n# Define context vector fields\ncontext_vector = ['time']\n\n# Dictionary to hold bandit learners for each user\nuser_bandits = {}\n\n# Loop over unique users\nfor user_id in unique_users:\n    # Filter DataFrame for current user\n    user_df = df[df['userid'] == user_id]\n    \n    # Initialize a new bandit learner for the current user\n    user_bandits[user_id] = ContextualLearner(SGDRegressor, None)\n    \n    # Loop over records for the current user\n    for index, record in user_df.iterrows():\n        # Get context vector\n        ctx_vec = record[context_vector].tolist()\n        # Simple normalization for age\n        ctx_vec[0] = ctx_vec[0] / 100.\n        # Get recommendation - action or arm\n        arm = record['query']\n        # Get reward scalar value - rating given by user\n        rew = record['reward']\n        # Predict reward\n        rew_pred = user_bandits[user_id].predict(ctx_vec, arm)\n        # Train the bandit learner\n        user_bandits[user_id].train(ctx_vec, arm, rew)\n\n# Now, you can use the trained bandit learners for each user as needed\n# For example, to predict rewards for a specific time for each user:\ntime = int(input(\"Enter time: \"))\nreward_lists = {}  # Dictionary to hold reward lists for each user\n\nfor user_id, bandit in user_bandits.items():\n    # Assuming df is your DataFrame containing user data\n    user_df = df[df['userid'] == user_id]\n    \n    # Initialize reward list for the current user\n    reward_list = []\n    \n    # Loop over records for the current user\n    for index, record in user_df.iterrows():\n        # Get context vector\n        ctx_vec = record[context_vector].tolist()\n        # Simple normalization for age\n        ctx_vec[0] = ctx_vec[0] / 100.\n        # Get recommendation - action or arm\n        arm = record['query']\n        # Predict reward\n        rew_pred = bandit.predict(ctx_vec, arm)\n        reward_list.append(rew_pred)\n    \n    # Store the reward list for the current user\n    reward_lists[user_id] = reward_list\n\n# Now reward_lists dictionary contains reward lists for each user\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:38:24.551087Z","iopub.execute_input":"2024-03-15T18:38:24.552026Z","iopub.status.idle":"2024-03-15T18:38:43.773466Z","shell.execute_reply.started":"2024-03-15T18:38:24.551993Z","shell.execute_reply":"2024-03-15T18:38:43.772651Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter time:  3\n"}]},{"cell_type":"code","source":"def get_top_labels(user_id, num_labels=2):\n    # Check if the user ID exists in the bandit learners dictionary\n    if user_id in user_bandits:\n        # Get the bandit learner for the specified user\n        bandit = user_bandits[user_id]\n        \n        # Predict rewards for all possible actions\n        rewards = {}\n        num_actions = df['query'].nunique()\n\n        for action in range(num_actions):  # Assuming num_actions is defined somewhere\n            # Create a context vector (here, using default values, modify as needed)\n            ctx_vec = [0.5]  # Placeholder context vector\n            \n            # Predict reward for the current action\n            rew_pred = bandit.predict(ctx_vec, action)\n            rewards[action] = rew_pred\n        \n        # Sort actions based on predicted rewards\n        sorted_actions = sorted(rewards, key=rewards.get, reverse=True)\n        \n        # Get the top labels and their predicted rewards\n        top_labels = [sorted_actions[i] for i in range(min(num_labels, len(sorted_actions)))]\n        top_rewards = [rewards[action] for action in top_labels]\n        \n        return top_labels, top_rewards\n    else:\n        print(\"User ID not found.\")\n        return None, None\n\n# Example usage: taking user ID input and getting top labels\nuser_id = int(input(\"Enter user ID: \"))\ntop_labels, top_rewards = get_top_labels(user_id)\n\nif top_labels is not None:\n    print(\"Top labels for user {}: {}\".format(user_id, top_labels))\n    print(\"Corresponding rewards:\", top_rewards)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:41:38.555332Z","iopub.execute_input":"2024-03-15T18:41:38.555700Z","iopub.status.idle":"2024-03-15T18:41:40.763345Z","shell.execute_reply.started":"2024-03-15T18:41:38.555671Z","shell.execute_reply":"2024-03-15T18:41:40.762447Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter user ID:  4\n"},{"name":"stdout","text":"Top labels for user 4: [5, 0]\nCorresponding rewards: [0.06935503295674866, 0.06444238003781401]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test = train_test_split(df, test_size = 0.30, random_state = 42)\n\nprint(X_train.shape)\nprint(X_test.shape)\n\n\nuser_data = X_train.pivot_table(index = 'userid', columns = 'query', values = 'time', aggfunc='mean').fillna(0)\nuser_data.head()\n\n\n# make a copy of train and test datasets\ndummy_train = X_train.copy()\ndummy_test = X_test.copy()\n\ndummy_train['time'] = dummy_train['time'].apply(lambda x: 0 if x > 0 else 1)\ndummy_test['time'] = dummy_test['time'].apply(lambda x: 1 if x > 0 else 0)\n\n\n\n\n# The movies not rated by user is marked as 1 for prediction\ndummy_train = dummy_train.pivot_table(index = 'userid', columns = 'query', values = 'time', aggfunc='mean').fillna(1)\n\n# The movies not rated by user is marked as 0 for evaluation\ndummy_test = dummy_test.pivot_table(index ='userid', columns = 'query', values = 'time', aggfunc='mean').fillna(0)\n\n\ndummy_train.head()\ndummy_test.head()\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# User Similarity Matrix using Cosine similarity as a similarity measure between Users\nuser_similarity = cosine_similarity(user_data)\nuser_similarity[np.isnan(user_similarity)] = 0\nprint(user_similarity)\nprint(user_similarity.shape)\n\n\nuser_predicted_ratings = np.dot(user_similarity, user_data)\nuser_predicted_ratings\n\n\n\n\n# np.multiply for cell-by-cell multiplication\n\nuser_final_ratings = np.multiply(user_predicted_ratings, dummy_train)\nuser_final_ratings.head()\n\n\n\n\nuser_final_ratings.iloc[42].sort_values(ascending = False)[0:5]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T18:41:49.164992Z","iopub.execute_input":"2024-03-15T18:41:49.165846Z","iopub.status.idle":"2024-03-15T18:41:49.218730Z","shell.execute_reply.started":"2024-03-15T18:41:49.165808Z","shell.execute_reply":"2024-03-15T18:41:49.217811Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"(7000, 4)\n(3000, 4)\n[[1.         0.95320026 0.95348032 ... 0.9633914  0.90903211 0.97131143]\n [0.95320026 1.         0.95894915 ... 0.97724512 0.93504682 0.98445468]\n [0.95348032 0.95894915 1.         ... 0.97180626 0.93146521 0.97841628]\n ...\n [0.9633914  0.97724512 0.97180626 ... 1.         0.9639072  0.97513513]\n [0.90903211 0.93504682 0.93146521 ... 0.9639072  1.         0.93540072]\n [0.97131143 0.98445468 0.97841628 ... 0.97513513 0.93540072 1.        ]]\n(61, 61)\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"query\n3    59.250602\n7    43.651413\n1     0.000000\n0     0.000000\n4     0.000000\nName: 42, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}